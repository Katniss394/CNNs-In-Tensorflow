{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot graphs inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process the dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 5 batches, named data_batch_1, data_batch_2, etc.. Each batch contains the labels and images of the following:\n",
    "\n",
    "* 0 - airplane\n",
    "* 1 - automobile\n",
    "* 2 - bird\n",
    "* 3 - cat\n",
    "* 4 - deer\n",
    "* 5 - dog\n",
    "* 6 - frog\n",
    "* 7 - horse\n",
    "* 8 - ship\n",
    "* 9 - truck\n",
    "\n",
    "\n",
    "* Access the image and the labels from a single batch specified by id (1-5) and combine them \n",
    "* Reshape the images, the images are fed to the convolutional layer as a 4-D tensor.\n",
    "* Transpose the axes of the reshaped image to be in this form: *[batch_size, height, width, channels]*, **channels should be the last axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.empty((0, 32,32,3))\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    with open('cifar_10/data_batch_'+str(i+1), mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    new_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    features=np.append(features,new_features,axis=0)\n",
    "    new_labels = batch['labels']\n",
    "    labels.extend(new_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "* Map the integer labels to the actual labels for display\n",
    "* Plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', \n",
    "          'automobile', \n",
    "          'bird', \n",
    "          'cat', \n",
    "          'deer', \n",
    "          'dog', \n",
    "          'frog', \n",
    "          'horse', \n",
    "          'ship', \n",
    "          'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  bird\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x182c29e080>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181c37def0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Label: \", classes[labels[6]])\n",
    "plt.imshow(features[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(features) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features[:train_size,:,:]\n",
    "\n",
    "y_train = labels[:train_size]\n",
    "\n",
    "X_test = features[train_size:,:,:]\n",
    "\n",
    "y_test = labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining parameters\n",
    "\n",
    "* Each image is of size 32x32\n",
    "* The image is RGB so has 3 channels, and requires 3 numbers to represent each pixel\n",
    "* The training dataset placeholder can have any number of instances and each instance is an array of 32x32 pixels.\n",
    "* The images are fed to the convolutional layer as a 4D tensor *[batch_size, height, width, channels]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "n_inputs = height * width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,  height, width, channels], name=\"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a dropout layer to avoid overfitting the training data\n",
    "\n",
    "* The training flag is set to False during prediction and is True while training (dropout is applied only in the training phase)\n",
    "* The dropout_rate indicates the chances that a neuron is turned off during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.4\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "dropOut_1 = tf.layers.dropout(X, dropout_rate, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, shape=[None], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network design\n",
    "\n",
    "* 2 convolutional layers\n",
    "* 1 max pooling layer : The pooled image is only 1/4th the size of the original image with this kernel size and stride\n",
    "* 1 convolutional layer\n",
    "* 1 max pooling layer\n",
    "* flatten : Reshape the pooled layer to be a 1-D vector\n",
    "* 2 fully connected layers\n",
    "* Output layer : The number of outputs of the logits layer should be 10 as cifar has 10 classes of data.\n",
    "* apply the softmax activation as well as calculate the cross-entropy as our cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1 = tf.layers.conv2d(dropOut_1, filters=32,\n",
    "                         kernel_size=3,\n",
    "                         strides=1, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2 = tf.layers.conv2d(conv_1, filters=64, \n",
    "                         kernel_size=3,\n",
    "                         strides=2, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_3 = tf.nn.max_pool(conv_2,\n",
    "                       ksize=[1, 2, 2, 1],\n",
    "                       strides=[1, 2, 2, 1],\n",
    "                       padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_4 = tf.layers.conv2d(pool_3, filters=128, \n",
    "                         kernel_size=4,\n",
    "                         strides=3, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_5 = tf.nn.max_pool(conv_4,\n",
    "                       ksize=[1, 2, 2, 1],\n",
    "                       strides=[1, 1, 1, 1],\n",
    "                       padding=\"VALID\")\n",
    "\n",
    "pool_5_flat = tf.reshape(pool_5, shape=[-1, 128 * 2 * 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullyconn_1 = tf.layers.dense(pool_5_flat, 128,\n",
    "                             activation=tf.nn.relu, name=\"fc1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullyconn_2 = tf.layers.dense(fullyconn_1, 64,\n",
    "                             activation=tf.nn.relu, name=\"fc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.layers.dense(fullyconn_2, 10, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output,\n",
    "                                                          labels=y)\n",
    "loss = tf.reduce_mean(x_entropy)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "* Check whether the highest probability output is equal to the y-label\n",
    "* Check the accuracy across all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(output, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "* Ensure that dropout is enabled during training to avoid overfitting\n",
    "* Train on all the batches for more accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.215075 Test accuracy: 0.2114\n",
      "1 Train accuracy: 0.327275 Test accuracy: 0.3154\n",
      "2 Train accuracy: 0.425875 Test accuracy: 0.4145\n",
      "3 Train accuracy: 0.431075 Test accuracy: 0.4159\n",
      "4 Train accuracy: 0.470025 Test accuracy: 0.4489\n",
      "5 Train accuracy: 0.470725 Test accuracy: 0.4482\n",
      "6 Train accuracy: 0.497375 Test accuracy: 0.4715\n",
      "7 Train accuracy: 0.52245 Test accuracy: 0.4977\n",
      "8 Train accuracy: 0.54285 Test accuracy: 0.5067\n",
      "9 Train accuracy: 0.547925 Test accuracy: 0.5101\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "_BATCH_SIZE = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        batch_size = int(math.ceil(len(X_train) / _BATCH_SIZE))\n",
    "        for s in range(batch_size):\n",
    "            batch_xs = X_train[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]\n",
    "            batch_ys = y_train[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]\n",
    "\n",
    "            sess.run(training_op, feed_dict={X: batch_xs, y: batch_ys , training: True})\n",
    "\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
